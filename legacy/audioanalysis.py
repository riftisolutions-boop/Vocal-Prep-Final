# -*- coding: utf-8 -*-
"""audioanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qsjeprk3o7qjDqsSwDLofONJwjAb48bd

Installation of Libraries and Packages
"""

pip install pandas

pip install numpy

!pip install librosa pyAudioAnalysis

pip install moviepy

!pip install openai-whisper

from moviepy.editor import VideoFileClip

import warnings
warnings.filterwarnings("ignore", category=SyntaxWarning)

import librosa
import os
import pandas as pd
from pydub import AudioSegment
import numpy as np

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""Loading Files and Segregating the data into proper files"""

# List all files and folders in your Google Drive root
root_path = "/content/drive/MyDrive"
print("Files & folders in MyDrive:")
print(os.listdir(root_path))

print("Inside InterviewApp:")
print(os.listdir("/content/drive/MyDrive/Interview Preparation Project/Data/Audio_Files"))
print(os.listdir("/content/drive/MyDrive/Interview Preparation Project/Data/WAV_audio"))

"""MP4 to WAV conversion"""

root_path = "/content/drive/MyDrive"
print("Files & folders in MyDrive:")
print(os.listdir(root_path))

input_folder = "/content/drive/MyDrive/Interview Preparation Project/Data/Audio_Files"
output_folder = "/content/drive/MyDrive/Interview Preparation Project/Data/Wav_Files"
os.makedirs(output_folder, exist_ok=True)

print("\nInside Audio_Files:")
print(os.listdir(input_folder))

# Step 2: Convert MP4 to WAV
converted_files = []

for filename in os.listdir(input_folder):
    if filename.endswith(".mp4"):
        mp4_path = os.path.join(input_folder, filename)
        wav_path = os.path.join(output_folder, filename.replace(".mp4", ".wav"))

        try:
            print(f"Converting: {filename}")
            audio = AudioSegment.from_file(mp4_path, format="mp4")
            audio = audio.set_channels(1).set_frame_rate(16000)
            audio.export(wav_path, format="wav")
            converted_files.append(wav_path)
            print(f"Converted: {wav_path}")
        except Exception as e:
            print(f"Failed to convert {filename}: {e}")

"""Extraction of Features"""

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=16000)

    #Silence detection (pause segments)
    non_silent_intervals = librosa.effects.split(y, top_db=30)
    pause_count = len(non_silent_intervals) - 1 if len(non_silent_intervals) > 1 else 0

    total_silence = 0
    for i in range(1, len(non_silent_intervals)):
        prev_end = non_silent_intervals[i - 1][1]
        curr_start = non_silent_intervals[i][0]
        total_silence += (curr_start - prev_end) / sr

    # Speaking rate (words/sec) â€” simple proxy using energy peaks
    duration = librosa.get_duration(y=y, sr=sr)
    energy = np.square(y)
    energy_threshold = 0.02 * np.max(energy)
    voiced_frames = energy > energy_threshold
    voiced_duration = np.sum(voiced_frames) / sr
    speaking_rate = voiced_duration / duration if duration > 0 else 0

    # Pitch features
    try:
        pitches, _, _ = librosa.pyin(y, fmin=50, fmax=300, sr=sr)
        pitch_mean = np.nanmean(pitches)
        pitch_std = np.nanstd(pitches)
    except Exception as e:
        print(f"Pitch extraction failed for {file_path}: {e}")
        pitch_mean, pitch_std = None, None

    # Feature dictionary
    features = {
        'filename': os.path.basename(file_path),
        'duration': duration,
        'zcr_mean': np.mean(librosa.feature.zero_crossing_rate(y)[0]),
        'energy_mean': np.mean(energy),
        'energy_std': np.std(energy),
        'rms_mean': np.mean(librosa.feature.rms(y=y)),
        'pitch_mean': pitch_mean,
        'pitch_std': pitch_std,
        'speaking_rate': speaking_rate,
        'pause_count': pause_count,
        'pause_duration': total_silence
    }

    return features

# Extract from all .wav files
input_folder = "/content/drive/MyDrive/Interview Preparation Project/Data/WAV_audio"
all_features = []

for fname in os.listdir(input_folder):
    if fname.endswith(".wav"):
        fpath = os.path.join(input_folder, fname)
        try:
            feats = extract_features(fpath)
            all_features.append(feats)
        except Exception as e:
            print(f" Error with {fname}: {e}")

df = pd.DataFrame(all_features)
df.to_csv("/content/drive/MyDrive/Interview Preparation Project/audio_features1.csv", index=False)
print("Features saved!")

"""Transcriptions"""

import whisper
import os

# Load the whisper model (base is fast and good, medium/large more accurate)
model = whisper.load_model("base")  # try "small", "medium" or "large" for better accuracy

# Directory with your audio files
audio_folder = "/content/drive/MyDrive/Interview Preparation Project/Data/WAV_audio"

# Loop through all wav files
for file in os.listdir(audio_folder):
    if file.endswith(".wav"):
        audio_path = os.path.join(audio_folder, file)
        result = model.transcribe(audio_path)
        print(f"Transcription for {file}:\n{result['text']}\n")

transcriptions = []

for file in os.listdir(audio_folder):
    if file.endswith(".wav"):
        audio_path = os.path.join(audio_folder, file)
        result = model.transcribe(audio_path)
        transcriptions.append({
            "filename": file,
            "transcription": result['text']
        })

df = pd.DataFrame(transcriptions)
df.to_csv("/content/drive/MyDrive/Interview Preparation Project/transcriptions.csv", index=False)

