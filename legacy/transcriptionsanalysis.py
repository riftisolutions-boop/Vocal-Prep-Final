# -*- coding: utf-8 -*-
"""transcriptionsanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HSaoCKrzLrawCeWC9YtDsVxiS0wbPASf
"""

!pip install whisper

!pip install vaderSentiment textstat spacy
!python -m spacy download en_core_web_sm

import whisper
import pandas as pd
import re
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import textstat
import spacy

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

df = pd.read_csv("/content/drive/MyDrive/Interview Preparation Project/transcriptions.csv")
df.head()

nlp = spacy.load("en_core_web_sm")

df['clean_text'] = df['transcription'].apply(lambda x: re.sub(r'[^\w\s]', '', str(x).lower()))

df.head()

# Word count
df['word_count'] = df['clean_text'].apply(lambda x: len(x.split()))

# Count filler words
filler_words = ['um', 'uh', 'er', 'ah', 'hmm','like', 'you know', 'i mean', 'sort of', 'kind of', 'i guess',
    'maybe', 'probably', 'i think', 'i suppose', 'i believe', 'i feel like',
    'let me think', 'what iâ€™m trying to say is', 'basically', 'actually',
    'honestly', 'well', 'so', 'just', 'okay', 'right', 'now', 'anyway']
df['filler_count'] = df['clean_text'].apply(lambda x: sum(x.count(word) for word in filler_words))

df['filler_rate'] = df['filler_count'] / df['word_count']

df.head()

df["filler_count"].value_counts()

hedge_words = ['maybe', 'i guess', 'probably', 'sort of', 'kind of', 'i think', 'i suppose']
df['hedge_count'] = df['clean_text'].apply(lambda x: sum(x.count(word) for word in hedge_words))

pronouns = ['i', 'me', 'my']
df['pronoun_count'] = df['clean_text'].apply(lambda x: sum(x.split().count(word) for word in pronouns))
df['pronoun_rate'] = df['pronoun_count'] / df['word_count']

df['sentence_count'] = df['transcription'].apply(lambda x: len(re.findall(r'[.!?]', str(x))))
df['sentence_count'] = df['sentence_count'].replace(0, 1)  # to avoid division by zero

# Avg sentence length
df['avg_sentence_length'] = df['word_count'] / df['sentence_count']

# Fill missing transcriptions with empty string to avoid TypeError
df['transcription'] = df['transcription'].fillna("")

# Now apply textstat safely
df['flesch_reading_ease'] = df['transcription'].apply(lambda x: textstat.flesch_reading_ease(str(x)))
df['smog_index'] = df['transcription'].apply(lambda x: textstat.smog_index(str(x)))

df['polarity'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)
df['subjectivity'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)

analyzer = SentimentIntensityAnalyzer()
df['vader_score'] = df['clean_text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])

def get_sentiment_class(text):
    score = analyzer.polarity_scores(str(text))['compound']
    if score >= 0.05:
        return 'positive'
    elif score <= -0.05:
        return 'negative'
    else:
        return 'neutral'

df['sentiment'] = df['transcription'].apply(get_sentiment_class)

# POS tagging: modal verbs, adverbs, total verbs
def get_pos_ratios(text):
    doc = nlp(text)
    modal_count = sum(1 for token in doc if token.tag_ == 'MD')
    adverb_count = sum(1 for token in doc if token.pos_ == 'ADV')
    verb_count = sum(1 for token in doc if token.pos_ == 'VERB')
    total_tokens = len(doc)
    return pd.Series({
        'modal_pct': modal_count / total_tokens if total_tokens else 0,
        'adverb_pct': adverb_count / total_tokens if total_tokens else 0,
        'verb_pct': verb_count / total_tokens if total_tokens else 0
    })

pos_features = df['transcription'].apply(get_pos_ratios)
df = pd.concat([df, pos_features], axis=1)

df.head()

df.to_csv("/content/drive/MyDrive/Interview Preparation Project/transcriptions_feature_extracted.csv", index=False)